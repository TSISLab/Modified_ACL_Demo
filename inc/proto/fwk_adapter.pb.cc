// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: fwk_adapter.proto

#include "fwk_adapter.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>
extern PROTOBUF_INTERNAL_EXPORT_fwk_5fadapter_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<0> scc_info_TensorDataInfo_fwk_5fadapter_2eproto;
namespace aicpu {
namespace FWKAdapter {
class TensorDataInfoDefaultTypeInternal {
 public:
  ::PROTOBUF_NAMESPACE_ID::internal::ExplicitlyConstructed<TensorDataInfo> _instance;
} _TensorDataInfo_default_instance_;
class KernelRunParamDefaultTypeInternal {
 public:
  ::PROTOBUF_NAMESPACE_ID::internal::ExplicitlyConstructed<KernelRunParam> _instance;
} _KernelRunParam_default_instance_;
}  // namespace FWKAdapter
}  // namespace aicpu
static void InitDefaultsscc_info_KernelRunParam_fwk_5fadapter_2eproto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::aicpu::FWKAdapter::_KernelRunParam_default_instance_;
    new (ptr) ::aicpu::FWKAdapter::KernelRunParam();
    ::PROTOBUF_NAMESPACE_ID::internal::OnShutdownDestroyMessage(ptr);
  }
  ::aicpu::FWKAdapter::KernelRunParam::InitAsDefaultInstance();
}

::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<1> scc_info_KernelRunParam_fwk_5fadapter_2eproto =
    {{ATOMIC_VAR_INIT(::PROTOBUF_NAMESPACE_ID::internal::SCCInfoBase::kUninitialized), 1, 0, InitDefaultsscc_info_KernelRunParam_fwk_5fadapter_2eproto}, {
      &scc_info_TensorDataInfo_fwk_5fadapter_2eproto.base,}};

static void InitDefaultsscc_info_TensorDataInfo_fwk_5fadapter_2eproto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::aicpu::FWKAdapter::_TensorDataInfo_default_instance_;
    new (ptr) ::aicpu::FWKAdapter::TensorDataInfo();
    ::PROTOBUF_NAMESPACE_ID::internal::OnShutdownDestroyMessage(ptr);
  }
  ::aicpu::FWKAdapter::TensorDataInfo::InitAsDefaultInstance();
}

::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<0> scc_info_TensorDataInfo_fwk_5fadapter_2eproto =
    {{ATOMIC_VAR_INIT(::PROTOBUF_NAMESPACE_ID::internal::SCCInfoBase::kUninitialized), 0, 0, InitDefaultsscc_info_TensorDataInfo_fwk_5fadapter_2eproto}, {}};

static ::PROTOBUF_NAMESPACE_ID::Metadata file_level_metadata_fwk_5fadapter_2eproto[2];
static constexpr ::PROTOBUF_NAMESPACE_ID::EnumDescriptor const** file_level_enum_descriptors_fwk_5fadapter_2eproto = nullptr;
static constexpr ::PROTOBUF_NAMESPACE_ID::ServiceDescriptor const** file_level_service_descriptors_fwk_5fadapter_2eproto = nullptr;

const ::PROTOBUF_NAMESPACE_ID::uint32 TableStruct_fwk_5fadapter_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::aicpu::FWKAdapter::TensorDataInfo, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  PROTOBUF_FIELD_OFFSET(::aicpu::FWKAdapter::TensorDataInfo, dtype_),
  PROTOBUF_FIELD_OFFSET(::aicpu::FWKAdapter::TensorDataInfo, dim_),
  PROTOBUF_FIELD_OFFSET(::aicpu::FWKAdapter::TensorDataInfo, data_addr_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::aicpu::FWKAdapter::KernelRunParam, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  PROTOBUF_FIELD_OFFSET(::aicpu::FWKAdapter::KernelRunParam, input_),
  PROTOBUF_FIELD_OFFSET(::aicpu::FWKAdapter::KernelRunParam, output_),
};
static const ::PROTOBUF_NAMESPACE_ID::internal::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, sizeof(::aicpu::FWKAdapter::TensorDataInfo)},
  { 8, -1, sizeof(::aicpu::FWKAdapter::KernelRunParam)},
};

static ::PROTOBUF_NAMESPACE_ID::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::aicpu::FWKAdapter::_TensorDataInfo_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::aicpu::FWKAdapter::_KernelRunParam_default_instance_),
};

const char descriptor_table_protodef_fwk_5fadapter_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n\021fwk_adapter.proto\022\020aicpu.FWKAdapter\"\?\n"
  "\016TensorDataInfo\022\r\n\005dtype\030\001 \001(\r\022\013\n\003dim\030\002 "
  "\003(\003\022\021\n\tdata_addr\030\003 \001(\003\"s\n\016KernelRunParam"
  "\022/\n\005input\030\001 \003(\0132 .aicpu.FWKAdapter.Tenso"
  "rDataInfo\0220\n\006output\030\002 \003(\0132 .aicpu.FWKAda"
  "pter.TensorDataInfoB\003\370\001\001b\006proto3"
  ;
static const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable*const descriptor_table_fwk_5fadapter_2eproto_deps[1] = {
};
static ::PROTOBUF_NAMESPACE_ID::internal::SCCInfoBase*const descriptor_table_fwk_5fadapter_2eproto_sccs[2] = {
  &scc_info_KernelRunParam_fwk_5fadapter_2eproto.base,
  &scc_info_TensorDataInfo_fwk_5fadapter_2eproto.base,
};
static ::PROTOBUF_NAMESPACE_ID::internal::once_flag descriptor_table_fwk_5fadapter_2eproto_once;
const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_fwk_5fadapter_2eproto = {
  false, false, descriptor_table_protodef_fwk_5fadapter_2eproto, "fwk_adapter.proto", 232,
  &descriptor_table_fwk_5fadapter_2eproto_once, descriptor_table_fwk_5fadapter_2eproto_sccs, descriptor_table_fwk_5fadapter_2eproto_deps, 2, 0,
  schemas, file_default_instances, TableStruct_fwk_5fadapter_2eproto::offsets,
  file_level_metadata_fwk_5fadapter_2eproto, 2, file_level_enum_descriptors_fwk_5fadapter_2eproto, file_level_service_descriptors_fwk_5fadapter_2eproto,
};

// Force running AddDescriptors() at dynamic initialization time.
static bool dynamic_init_dummy_fwk_5fadapter_2eproto = (static_cast<void>(::PROTOBUF_NAMESPACE_ID::internal::AddDescriptors(&descriptor_table_fwk_5fadapter_2eproto)), true);
namespace aicpu {
namespace FWKAdapter {

// ===================================================================

void TensorDataInfo::InitAsDefaultInstance() {
}
class TensorDataInfo::_Internal {
 public:
};

TensorDataInfo::TensorDataInfo(::PROTOBUF_NAMESPACE_ID::Arena* arena)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena),
  dim_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:aicpu.FWKAdapter.TensorDataInfo)
}
TensorDataInfo::TensorDataInfo(const TensorDataInfo& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      dim_(from.dim_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&data_addr_, &from.data_addr_,
    static_cast<size_t>(reinterpret_cast<char*>(&dtype_) -
    reinterpret_cast<char*>(&data_addr_)) + sizeof(dtype_));
  // @@protoc_insertion_point(copy_constructor:aicpu.FWKAdapter.TensorDataInfo)
}

void TensorDataInfo::SharedCtor() {
  ::memset(&data_addr_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&dtype_) -
      reinterpret_cast<char*>(&data_addr_)) + sizeof(dtype_));
}

TensorDataInfo::~TensorDataInfo() {
  // @@protoc_insertion_point(destructor:aicpu.FWKAdapter.TensorDataInfo)
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

void TensorDataInfo::SharedDtor() {
  GOOGLE_DCHECK(GetArena() == nullptr);
}

void TensorDataInfo::ArenaDtor(void* object) {
  TensorDataInfo* _this = reinterpret_cast< TensorDataInfo* >(object);
  (void)_this;
}
void TensorDataInfo::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void TensorDataInfo::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const TensorDataInfo& TensorDataInfo::default_instance() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&::scc_info_TensorDataInfo_fwk_5fadapter_2eproto.base);
  return *internal_default_instance();
}


void TensorDataInfo::Clear() {
// @@protoc_insertion_point(message_clear_start:aicpu.FWKAdapter.TensorDataInfo)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  dim_.Clear();
  ::memset(&data_addr_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&dtype_) -
      reinterpret_cast<char*>(&data_addr_)) + sizeof(dtype_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* TensorDataInfo::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  ::PROTOBUF_NAMESPACE_ID::Arena* arena = GetArena(); (void)arena;
  while (!ctx->Done(&ptr)) {
    ::PROTOBUF_NAMESPACE_ID::uint32 tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    CHK_(ptr);
    switch (tag >> 3) {
      // uint32 dtype = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 8)) {
          dtype_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      // repeated int64 dim = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 18)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt64Parser(_internal_mutable_dim(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 16) {
          _internal_add_dim(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr));
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      // int64 data_addr = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 24)) {
          data_addr_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      default: {
      handle_unusual:
        if ((tag & 7) == 4 || tag == 0) {
          ctx->SetLastTag(tag);
          goto success;
        }
        ptr = UnknownFieldParse(tag,
            _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
            ptr, ctx);
        CHK_(ptr != nullptr);
        continue;
      }
    }  // switch
  }  // while
success:
  return ptr;
failure:
  ptr = nullptr;
  goto success;
#undef CHK_
}

::PROTOBUF_NAMESPACE_ID::uint8* TensorDataInfo::_InternalSerialize(
    ::PROTOBUF_NAMESPACE_ID::uint8* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:aicpu.FWKAdapter.TensorDataInfo)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // uint32 dtype = 1;
  if (this->dtype() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteUInt32ToArray(1, this->_internal_dtype(), target);
  }

  // repeated int64 dim = 2;
  {
    int byte_size = _dim_cached_byte_size_.load(std::memory_order_relaxed);
    if (byte_size > 0) {
      target = stream->WriteInt64Packed(
          2, _internal_dim(), byte_size, target);
    }
  }

  // int64 data_addr = 3;
  if (this->data_addr() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt64ToArray(3, this->_internal_data_addr(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:aicpu.FWKAdapter.TensorDataInfo)
  return target;
}

size_t TensorDataInfo::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:aicpu.FWKAdapter.TensorDataInfo)
  size_t total_size = 0;

  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated int64 dim = 2;
  {
    size_t data_size = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      Int64Size(this->dim_);
    if (data_size > 0) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32Size(
            static_cast<::PROTOBUF_NAMESPACE_ID::int32>(data_size));
    }
    int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(data_size);
    _dim_cached_byte_size_.store(cached_size,
                                    std::memory_order_relaxed);
    total_size += data_size;
  }

  // int64 data_addr = 3;
  if (this->data_addr() != 0) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int64Size(
        this->_internal_data_addr());
  }

  // uint32 dtype = 1;
  if (this->dtype() != 0) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::UInt32Size(
        this->_internal_dtype());
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    return ::PROTOBUF_NAMESPACE_ID::internal::ComputeUnknownFieldsSize(
        _internal_metadata_, total_size, &_cached_size_);
  }
  int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void TensorDataInfo::MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:aicpu.FWKAdapter.TensorDataInfo)
  GOOGLE_DCHECK_NE(&from, this);
  const TensorDataInfo* source =
      ::PROTOBUF_NAMESPACE_ID::DynamicCastToGenerated<TensorDataInfo>(
          &from);
  if (source == nullptr) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:aicpu.FWKAdapter.TensorDataInfo)
    ::PROTOBUF_NAMESPACE_ID::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:aicpu.FWKAdapter.TensorDataInfo)
    MergeFrom(*source);
  }
}

void TensorDataInfo::MergeFrom(const TensorDataInfo& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:aicpu.FWKAdapter.TensorDataInfo)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  dim_.MergeFrom(from.dim_);
  if (from.data_addr() != 0) {
    _internal_set_data_addr(from._internal_data_addr());
  }
  if (from.dtype() != 0) {
    _internal_set_dtype(from._internal_dtype());
  }
}

void TensorDataInfo::CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:aicpu.FWKAdapter.TensorDataInfo)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void TensorDataInfo::CopyFrom(const TensorDataInfo& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:aicpu.FWKAdapter.TensorDataInfo)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool TensorDataInfo::IsInitialized() const {
  return true;
}

void TensorDataInfo::InternalSwap(TensorDataInfo* other) {
  using std::swap;
  _internal_metadata_.Swap<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(&other->_internal_metadata_);
  dim_.InternalSwap(&other->dim_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(TensorDataInfo, dtype_)
      + sizeof(TensorDataInfo::dtype_)
      - PROTOBUF_FIELD_OFFSET(TensorDataInfo, data_addr_)>(
          reinterpret_cast<char*>(&data_addr_),
          reinterpret_cast<char*>(&other->data_addr_));
}

::PROTOBUF_NAMESPACE_ID::Metadata TensorDataInfo::GetMetadata() const {
  return GetMetadataStatic();
}


// ===================================================================

void KernelRunParam::InitAsDefaultInstance() {
}
class KernelRunParam::_Internal {
 public:
};

KernelRunParam::KernelRunParam(::PROTOBUF_NAMESPACE_ID::Arena* arena)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena),
  input_(arena),
  output_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:aicpu.FWKAdapter.KernelRunParam)
}
KernelRunParam::KernelRunParam(const KernelRunParam& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      input_(from.input_),
      output_(from.output_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:aicpu.FWKAdapter.KernelRunParam)
}

void KernelRunParam::SharedCtor() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&scc_info_KernelRunParam_fwk_5fadapter_2eproto.base);
}

KernelRunParam::~KernelRunParam() {
  // @@protoc_insertion_point(destructor:aicpu.FWKAdapter.KernelRunParam)
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

void KernelRunParam::SharedDtor() {
  GOOGLE_DCHECK(GetArena() == nullptr);
}

void KernelRunParam::ArenaDtor(void* object) {
  KernelRunParam* _this = reinterpret_cast< KernelRunParam* >(object);
  (void)_this;
}
void KernelRunParam::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void KernelRunParam::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const KernelRunParam& KernelRunParam::default_instance() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&::scc_info_KernelRunParam_fwk_5fadapter_2eproto.base);
  return *internal_default_instance();
}


void KernelRunParam::Clear() {
// @@protoc_insertion_point(message_clear_start:aicpu.FWKAdapter.KernelRunParam)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  input_.Clear();
  output_.Clear();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* KernelRunParam::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  ::PROTOBUF_NAMESPACE_ID::Arena* arena = GetArena(); (void)arena;
  while (!ctx->Done(&ptr)) {
    ::PROTOBUF_NAMESPACE_ID::uint32 tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    CHK_(ptr);
    switch (tag >> 3) {
      // repeated .aicpu.FWKAdapter.TensorDataInfo input = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 10)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_input(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<10>(ptr));
        } else goto handle_unusual;
        continue;
      // repeated .aicpu.FWKAdapter.TensorDataInfo output = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 18)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_output(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<18>(ptr));
        } else goto handle_unusual;
        continue;
      default: {
      handle_unusual:
        if ((tag & 7) == 4 || tag == 0) {
          ctx->SetLastTag(tag);
          goto success;
        }
        ptr = UnknownFieldParse(tag,
            _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
            ptr, ctx);
        CHK_(ptr != nullptr);
        continue;
      }
    }  // switch
  }  // while
success:
  return ptr;
failure:
  ptr = nullptr;
  goto success;
#undef CHK_
}

::PROTOBUF_NAMESPACE_ID::uint8* KernelRunParam::_InternalSerialize(
    ::PROTOBUF_NAMESPACE_ID::uint8* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:aicpu.FWKAdapter.KernelRunParam)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // repeated .aicpu.FWKAdapter.TensorDataInfo input = 1;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->_internal_input_size()); i < n; i++) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(1, this->_internal_input(i), target, stream);
  }

  // repeated .aicpu.FWKAdapter.TensorDataInfo output = 2;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->_internal_output_size()); i < n; i++) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, this->_internal_output(i), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:aicpu.FWKAdapter.KernelRunParam)
  return target;
}

size_t KernelRunParam::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:aicpu.FWKAdapter.KernelRunParam)
  size_t total_size = 0;

  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .aicpu.FWKAdapter.TensorDataInfo input = 1;
  total_size += 1UL * this->_internal_input_size();
  for (const auto& msg : this->input_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated .aicpu.FWKAdapter.TensorDataInfo output = 2;
  total_size += 1UL * this->_internal_output_size();
  for (const auto& msg : this->output_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    return ::PROTOBUF_NAMESPACE_ID::internal::ComputeUnknownFieldsSize(
        _internal_metadata_, total_size, &_cached_size_);
  }
  int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void KernelRunParam::MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:aicpu.FWKAdapter.KernelRunParam)
  GOOGLE_DCHECK_NE(&from, this);
  const KernelRunParam* source =
      ::PROTOBUF_NAMESPACE_ID::DynamicCastToGenerated<KernelRunParam>(
          &from);
  if (source == nullptr) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:aicpu.FWKAdapter.KernelRunParam)
    ::PROTOBUF_NAMESPACE_ID::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:aicpu.FWKAdapter.KernelRunParam)
    MergeFrom(*source);
  }
}

void KernelRunParam::MergeFrom(const KernelRunParam& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:aicpu.FWKAdapter.KernelRunParam)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  input_.MergeFrom(from.input_);
  output_.MergeFrom(from.output_);
}

void KernelRunParam::CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:aicpu.FWKAdapter.KernelRunParam)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void KernelRunParam::CopyFrom(const KernelRunParam& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:aicpu.FWKAdapter.KernelRunParam)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool KernelRunParam::IsInitialized() const {
  return true;
}

void KernelRunParam::InternalSwap(KernelRunParam* other) {
  using std::swap;
  _internal_metadata_.Swap<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(&other->_internal_metadata_);
  input_.InternalSwap(&other->input_);
  output_.InternalSwap(&other->output_);
}

::PROTOBUF_NAMESPACE_ID::Metadata KernelRunParam::GetMetadata() const {
  return GetMetadataStatic();
}


// @@protoc_insertion_point(namespace_scope)
}  // namespace FWKAdapter
}  // namespace aicpu
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::aicpu::FWKAdapter::TensorDataInfo* Arena::CreateMaybeMessage< ::aicpu::FWKAdapter::TensorDataInfo >(Arena* arena) {
  return Arena::CreateMessageInternal< ::aicpu::FWKAdapter::TensorDataInfo >(arena);
}
template<> PROTOBUF_NOINLINE ::aicpu::FWKAdapter::KernelRunParam* Arena::CreateMaybeMessage< ::aicpu::FWKAdapter::KernelRunParam >(Arena* arena) {
  return Arena::CreateMessageInternal< ::aicpu::FWKAdapter::KernelRunParam >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
